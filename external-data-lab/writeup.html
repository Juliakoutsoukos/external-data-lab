<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Write-up – External Data Lab</title>
    <script src="https://cdn.tailwindcss.com"></script>
  </head>

  <body class="min-h-screen bg-slate-950 text-slate-100">
    <header class="border-b border-slate-800">
      <div class="mx-auto max-w-4xl px-4 py-6">
        <h1 class="text-2xl font-bold tracking-tight">Write-up</h1>
        <nav class="mt-4 flex gap-4 text-sm">
          <a class="text-slate-200 hover:text-white underline underline-offset-4" href="./index.html">Home</a>
          <a class="text-slate-200 hover:text-white underline underline-offset-4" href="./writeup.html">Write-up</a>
        </nav>
      </div>
    </header>

    <main class="mx-auto max-w-4xl px-4 py-10">
      <article class="rounded-2xl border border-slate-800 bg-slate-900/30 p-6 leading-relaxed">
        <h2 class="text-xl font-semibold">AI Tool Reflection</h2>

        <p class="mt-4 text-slate-200">
          For this lab, I used Copilot with two different models and compared how well they helped me
          build a page that fetches data from two API endpoints and renders it using Alpine.js. One model
          was better at explaining why script load order matters (Tailwind → Alpine → module scripts) and
          suggested splitting fetch logic into a separate file for clarity. The other model produced code
          quickly, but I still had to debug details like module import paths and Alpine component mounting.
          Overall, AI sped up scaffolding and gave useful patterns, but I needed to test in the browser console,
          fix small errors, and verify the API fields to get everything fully working.
        </p>

        <p class="mt-6 text-sm text-slate-400">
          Replace the generic text above with your real Copilot prompts + model names (required).
        </p>
      </article>
    </main>
  </body>
</html>
